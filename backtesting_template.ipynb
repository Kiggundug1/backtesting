{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G3kKKxoL1xNo"
   },
   "source": [
    "<h3>Imports<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "ix8j_V3gWOt5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Abb1eUJ_Qmcl"
   },
   "source": [
    "**<h4>Inputs<h4>**\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_local_data(folder_path, symbol, start_year=2019, end_year=2024):\n",
    "    \"\"\"\n",
    "    Load and combine CSV files from a local folder using the format DAT_ASCII_EURUSD_M1_2019.csv.\n",
    "    Handles files with no header and semicolon-separated values.\n",
    "    \"\"\"\n",
    "    import os\n",
    "    import pandas as pd\n",
    "\n",
    "    all_data = []\n",
    "    for year in range(start_year, end_year + 1):\n",
    "        file_path = os.path.join(\n",
    "            folder_path, f\"DAT_ASCII_{symbol.upper()}_M1_{year}.csv\"\n",
    "        )\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\"Loading data from {file_path}\")\n",
    "            df = pd.read_csv(\n",
    "                file_path,\n",
    "                sep=\";\",\n",
    "                header=None,\n",
    "                names=[\"datetime\", \"open\", \"high\", \"low\", \"close\", \"volume\"],\n",
    "                engine=\"python\"\n",
    "            )\n",
    "            # Parse datetime\n",
    "            df['timestamp'] = pd.to_datetime(df['datetime'], format='%Y%m%d %H%M%S')\n",
    "            all_data.append(df)\n",
    "        else:\n",
    "            print(f\"Warning: File not found - {file_path}\")\n",
    "\n",
    "    if not all_data:\n",
    "        raise ValueError(\"No data files were found!\")\n",
    "\n",
    "    combined_data = pd.concat(all_data, ignore_index=True)\n",
    "    combined_data = combined_data.sort_values('timestamp')\n",
    "    return combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(data, timeframe):\n",
    "    \"\"\"\n",
    "    Resample data to a different timeframe.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Input dataframe with OHLC data\n",
    "    timeframe (str): Target timeframe (e.g., '5min', '15min', '1h', '4h', '1d')\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Resampled dataframe\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Set timestamp as index for resampling\n",
    "    df = df.set_index('timestamp')\n",
    "    \n",
    "    # Map common timeframe strings to pandas resample rule\n",
    "    timeframe_map = {\n",
    "        '1min': '1min',\n",
    "        '5min': '5min', \n",
    "        '15min': '15min',\n",
    "        '30min': '30min',\n",
    "        '1h': '1h',\n",
    "        '4h': '4h',\n",
    "        '1d': 'D'\n",
    "    }\n",
    "    \n",
    "    # Get the appropriate resample rule\n",
    "    resample_rule = timeframe_map.get(timeframe, timeframe)\n",
    "    \n",
    "    # Resample the data\n",
    "    resampled = df.resample(resample_rule).agg({\n",
    "        'open': 'first',\n",
    "        'high': 'max',\n",
    "        'low': 'min',\n",
    "        'close': 'last',\n",
    "        'volume': 'sum' if 'volume' in df.columns else None\n",
    "    }).dropna()\n",
    "    \n",
    "    # Reset index to get timestamp as a column again\n",
    "    resampled = resampled.reset_index()\n",
    "    \n",
    "    return resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VLyBtxe4Xn6U"
   },
   "source": [
    "<h3>Asset<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "-Ox7M5AMXn6V"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2019.csv\n",
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2020.csv\n",
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2021.csv\n",
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2022.csv\n",
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2023.csv\n",
      "Loading data from D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\\DAT_ASCII_EURUSD_M1_2024.csv\n",
      "Resampling data to 1h timeframe\n",
      "Loaded 30310 1h candles from 2019-01-01 17:00:00 to 2023-12-29 16:00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 17:00:00</td>\n",
       "      <td>1.14598</td>\n",
       "      <td>1.14672</td>\n",
       "      <td>1.14598</td>\n",
       "      <td>1.14606</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 18:00:00</td>\n",
       "      <td>1.14605</td>\n",
       "      <td>1.14676</td>\n",
       "      <td>1.14566</td>\n",
       "      <td>1.14612</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 19:00:00</td>\n",
       "      <td>1.14612</td>\n",
       "      <td>1.14626</td>\n",
       "      <td>1.14543</td>\n",
       "      <td>1.14561</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 20:00:00</td>\n",
       "      <td>1.14561</td>\n",
       "      <td>1.14563</td>\n",
       "      <td>1.14457</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 21:00:00</td>\n",
       "      <td>1.14521</td>\n",
       "      <td>1.14533</td>\n",
       "      <td>1.14426</td>\n",
       "      <td>1.14456</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            timestamp     open     high      low    close  volume\n",
       "0 2019-01-01 17:00:00  1.14598  1.14672  1.14598  1.14606       0\n",
       "1 2019-01-01 18:00:00  1.14605  1.14676  1.14566  1.14612       0\n",
       "2 2019-01-01 19:00:00  1.14612  1.14626  1.14543  1.14561       0\n",
       "3 2019-01-01 20:00:00  1.14561  1.14563  1.14457  1.14521       0\n",
       "4 2019-01-01 21:00:00  1.14521  1.14533  1.14426  1.14456       0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define parameters\n",
    "name_base = \"EURUSD\"  # Already defined in your notebook\n",
    "name_quote = \"\"  # Not needed for FX data\n",
    "timeframe = \"1h\"  # Change this to your desired timeframe: 1min, 5min, 15min, 1h, 4h, 1d, etc.\n",
    "\n",
    "# Path to your data folder\n",
    "data_folder = r\"D:\\KGDFRY\\Forex Trading\\GitHub\\FX-1-Minute-Data\\eurusd\"\n",
    "\n",
    "# Date ranges for backtesting\n",
    "starting_date_backtest = \"2019-01-01\"\n",
    "ending_date_backtest = \"2023-12-31\"\n",
    "\n",
    "# Load the data from CSV files\n",
    "raw_data = load_local_data(data_folder, name_base.lower(), start_year=2019, end_year=2024)\n",
    "\n",
    "# If the timeframe is not 1min, resample the data\n",
    "if timeframe != \"1min\":\n",
    "    print(f\"Resampling data to {timeframe} timeframe\")\n",
    "    data = resample_data(raw_data, timeframe)\n",
    "else:\n",
    "    data = raw_data\n",
    "\n",
    "# Filter data for the backtest period\n",
    "data = data[(data['timestamp'] >= pd.to_datetime(starting_date_backtest)) & \n",
    "            (data['timestamp'] <= pd.to_datetime(ending_date_backtest))]\n",
    "\n",
    "print(f\"Loaded {len(data)} {timeframe} candles from {data['timestamp'].min()} to {data['timestamp'].max()}\")\n",
    "\n",
    "# Display the first few rows\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oES_jd7_Qwgi"
   },
   "source": [
    "<h3>Data<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "YKmhAS0oRSKT"
   },
   "outputs": [],
   "source": [
    "timeframe = \"15m\"\n",
    "starting_date_backtest = \"01 january 2020\"\n",
    "ending_date_backtest =  \"31 december 2024\"\n",
    "starting_date_dl = \"01 january 2019\"\n",
    "ending_date_dl = \"31 december 2024\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZEUKrxLKRkDC"
   },
   "source": [
    "<h3>Portfolio<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e_RajxXLRxTB"
   },
   "outputs": [],
   "source": [
    "initial_capital = 100000 # in quote\n",
    "exposure = 2           # position size in percent\n",
    "# exposure = 'all'       # use this instead if you want 100% of your portfolio to be used for each trade\n",
    "trade_fees = 0.01       # in percent\n",
    "leverage = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4w2eRfduRkWh"
   },
   "source": [
    "<h4>Strategy flags<h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9PEt-7ltR730"
   },
   "outputs": [],
   "source": [
    "ignore_shorts = False\n",
    "ignore_longs = False\n",
    "\n",
    "ignore_tp = False\n",
    "ignore_sl = False\n",
    "ignore_exit = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F7wlCHRvS01O"
   },
   "source": [
    "**<h5>Strategy<h5>**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "w4l36OMnS6tu"
   },
   "outputs": [],
   "source": [
    "def compute_indicators(data): # check https://technical-analysis-library-in-python.readthedocs.io/en/latest/ta.html\n",
    "    data['EMAf'] = ta.trend.ema_indicator(data['close'], 10)\n",
    "    data['EMAs'] = ta.trend.ema_indicator(data['close'], 30)\n",
    "    data['Trend'] = ta.trend.sma_indicator(data['close'], 50)\n",
    "    data['RSI'] = ta.momentum.rsi(data['close'])\n",
    "    data['ATR'] = ta.volatility.average_true_range(data['high'], data['low'], data['close'], window=14)\n",
    "\n",
    "    # MACD = ta.trend.MACD(data['close'], window_slow=26, window_fast=12, window_sign=9)\n",
    "    # data['MACD'] = MACD.macd()\n",
    "    # data['MACD_histo'] = MACD.macd_diff()\n",
    "    # data['MACD_signal'] = MACD.macd_signal()\n",
    "\n",
    "    # BB = ta.volatility.BollingerBands(close=data['close'], window=100, window_dev=2)\n",
    "    # data[\"BB_lower\"] = BB.bollinger_lband()\n",
    "    # data[\"BB_upper\"] = BB.bollinger_hband()\n",
    "    # data[\"BB_avg\"] = BB.bollinger_mavg()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ubd_BB_USl2-"
   },
   "outputs": [],
   "source": [
    "def prepare_data(data, starting_date, ending_date):\n",
    "    \"\"\"\n",
    "    Prepare data for backtesting by computing indicators and filtering by date.\n",
    "    \n",
    "    Parameters:\n",
    "    data (pd.DataFrame): Input dataframe with OHLC data\n",
    "    starting_date (str): Start date for backtesting (YYYY-MM-DD)\n",
    "    ending_date (str): End date for backtesting (YYYY-MM-DD)\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Prepared dataframe with indicators\n",
    "    \"\"\"\n",
    "    data2 = data.copy()\n",
    "    data2 = compute_indicators(data2)  # Assuming this function exists in your notebook\n",
    "    \n",
    "    # Filter by date range\n",
    "    data2 = data2[(data2['timestamp'] >= pd.to_datetime(starting_date)) & \n",
    "                  (data2['timestamp'] <= pd.to_datetime(ending_date))]\n",
    "    \n",
    "    data2.dropna(inplace=True)\n",
    "    return data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "fFPjyukjTDa7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "      <th>volume</th>\n",
       "      <th>EMAf</th>\n",
       "      <th>EMAs</th>\n",
       "      <th>Trend</th>\n",
       "      <th>RSI</th>\n",
       "      <th>ATR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6213</th>\n",
       "      <td>2020-01-01 17:00:00</td>\n",
       "      <td>1.12120</td>\n",
       "      <td>1.12166</td>\n",
       "      <td>1.12106</td>\n",
       "      <td>1.12143</td>\n",
       "      <td>0</td>\n",
       "      <td>1.121790</td>\n",
       "      <td>1.121166</td>\n",
       "      <td>1.120558</td>\n",
       "      <td>50.856952</td>\n",
       "      <td>0.000907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6214</th>\n",
       "      <td>2020-01-01 18:00:00</td>\n",
       "      <td>1.12143</td>\n",
       "      <td>1.12218</td>\n",
       "      <td>1.12142</td>\n",
       "      <td>1.12188</td>\n",
       "      <td>0</td>\n",
       "      <td>1.121806</td>\n",
       "      <td>1.121212</td>\n",
       "      <td>1.120653</td>\n",
       "      <td>53.949483</td>\n",
       "      <td>0.000896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6215</th>\n",
       "      <td>2020-01-01 19:00:00</td>\n",
       "      <td>1.12188</td>\n",
       "      <td>1.12190</td>\n",
       "      <td>1.12157</td>\n",
       "      <td>1.12183</td>\n",
       "      <td>0</td>\n",
       "      <td>1.121810</td>\n",
       "      <td>1.121252</td>\n",
       "      <td>1.120732</td>\n",
       "      <td>53.546280</td>\n",
       "      <td>0.000856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6216</th>\n",
       "      <td>2020-01-01 20:00:00</td>\n",
       "      <td>1.12182</td>\n",
       "      <td>1.12244</td>\n",
       "      <td>1.12180</td>\n",
       "      <td>1.12209</td>\n",
       "      <td>0</td>\n",
       "      <td>1.121861</td>\n",
       "      <td>1.121306</td>\n",
       "      <td>1.120811</td>\n",
       "      <td>55.412395</td>\n",
       "      <td>0.000840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6217</th>\n",
       "      <td>2020-01-01 21:00:00</td>\n",
       "      <td>1.12210</td>\n",
       "      <td>1.12245</td>\n",
       "      <td>1.12184</td>\n",
       "      <td>1.12222</td>\n",
       "      <td>0</td>\n",
       "      <td>1.121926</td>\n",
       "      <td>1.121365</td>\n",
       "      <td>1.120880</td>\n",
       "      <td>56.356440</td>\n",
       "      <td>0.000824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30305</th>\n",
       "      <td>2023-12-29 12:00:00</td>\n",
       "      <td>1.10607</td>\n",
       "      <td>1.10667</td>\n",
       "      <td>1.10529</td>\n",
       "      <td>1.10639</td>\n",
       "      <td>0</td>\n",
       "      <td>1.106070</td>\n",
       "      <td>1.106917</td>\n",
       "      <td>1.108696</td>\n",
       "      <td>48.323129</td>\n",
       "      <td>0.001643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30306</th>\n",
       "      <td>2023-12-29 13:00:00</td>\n",
       "      <td>1.10640</td>\n",
       "      <td>1.10640</td>\n",
       "      <td>1.10491</td>\n",
       "      <td>1.10530</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105930</td>\n",
       "      <td>1.106812</td>\n",
       "      <td>1.108577</td>\n",
       "      <td>44.576017</td>\n",
       "      <td>0.001632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30307</th>\n",
       "      <td>2023-12-29 14:00:00</td>\n",
       "      <td>1.10532</td>\n",
       "      <td>1.10538</td>\n",
       "      <td>1.10381</td>\n",
       "      <td>1.10407</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105592</td>\n",
       "      <td>1.106636</td>\n",
       "      <td>1.108448</td>\n",
       "      <td>40.737210</td>\n",
       "      <td>0.001628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30308</th>\n",
       "      <td>2023-12-29 15:00:00</td>\n",
       "      <td>1.10409</td>\n",
       "      <td>1.10507</td>\n",
       "      <td>1.10383</td>\n",
       "      <td>1.10409</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105319</td>\n",
       "      <td>1.106471</td>\n",
       "      <td>1.108314</td>\n",
       "      <td>40.826445</td>\n",
       "      <td>0.001600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30309</th>\n",
       "      <td>2023-12-29 16:00:00</td>\n",
       "      <td>1.10411</td>\n",
       "      <td>1.10411</td>\n",
       "      <td>1.10339</td>\n",
       "      <td>1.10361</td>\n",
       "      <td>0</td>\n",
       "      <td>1.105008</td>\n",
       "      <td>1.106287</td>\n",
       "      <td>1.108184</td>\n",
       "      <td>39.297096</td>\n",
       "      <td>0.001537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24097 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                timestamp     open     high      low    close  volume  \\\n",
       "6213  2020-01-01 17:00:00  1.12120  1.12166  1.12106  1.12143       0   \n",
       "6214  2020-01-01 18:00:00  1.12143  1.12218  1.12142  1.12188       0   \n",
       "6215  2020-01-01 19:00:00  1.12188  1.12190  1.12157  1.12183       0   \n",
       "6216  2020-01-01 20:00:00  1.12182  1.12244  1.12180  1.12209       0   \n",
       "6217  2020-01-01 21:00:00  1.12210  1.12245  1.12184  1.12222       0   \n",
       "...                   ...      ...      ...      ...      ...     ...   \n",
       "30305 2023-12-29 12:00:00  1.10607  1.10667  1.10529  1.10639       0   \n",
       "30306 2023-12-29 13:00:00  1.10640  1.10640  1.10491  1.10530       0   \n",
       "30307 2023-12-29 14:00:00  1.10532  1.10538  1.10381  1.10407       0   \n",
       "30308 2023-12-29 15:00:00  1.10409  1.10507  1.10383  1.10409       0   \n",
       "30309 2023-12-29 16:00:00  1.10411  1.10411  1.10339  1.10361       0   \n",
       "\n",
       "           EMAf      EMAs     Trend        RSI       ATR  \n",
       "6213   1.121790  1.121166  1.120558  50.856952  0.000907  \n",
       "6214   1.121806  1.121212  1.120653  53.949483  0.000896  \n",
       "6215   1.121810  1.121252  1.120732  53.546280  0.000856  \n",
       "6216   1.121861  1.121306  1.120811  55.412395  0.000840  \n",
       "6217   1.121926  1.121365  1.120880  56.356440  0.000824  \n",
       "...         ...       ...       ...        ...       ...  \n",
       "30305  1.106070  1.106917  1.108696  48.323129  0.001643  \n",
       "30306  1.105930  1.106812  1.108577  44.576017  0.001632  \n",
       "30307  1.105592  1.106636  1.108448  40.737210  0.001628  \n",
       "30308  1.105319  1.106471  1.108314  40.826445  0.001600  \n",
       "30309  1.105008  1.106287  1.108184  39.297096  0.001537  \n",
       "\n",
       "[24097 rows x 11 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = prepare_data(data, starting_date_backtest, ending_date_backtest)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "93cmN-VcSJGf"
   },
   "source": [
    "<h3>Longs<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "y4fLfGswTQVs"
   },
   "outputs": [],
   "source": [
    "def check_long_entry_condition(row, previous_row):\n",
    "    return row['close'] > row['Trend'] and row['EMAf'] > row['EMAs'] and previous_row['EMAf'] < previous_row['EMAs'] and row['RSI'] < 70\n",
    "\n",
    "\n",
    "def check_long_exit_condition(row, previous_row):\n",
    "    return row['EMAf'] < row['EMAs'] and previous_row['EMAf'] > previous_row['EMAs']\n",
    "\n",
    "\n",
    "def compute_long_sl_level(row, entry_price):\n",
    "    return entry_price - 2 * row['ATR']\n",
    "\n",
    "\n",
    "def compute_long_tp_level(row, entry_price, stop_loss_price):\n",
    "    risk_reward_ratio = 4\n",
    "    return entry_price * (1 + risk_reward_ratio * (1 - stop_loss_price / entry_price))\n",
    "    # return row['open'] * 1.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHa8jM6wSJN0"
   },
   "source": [
    "<h3>Shorts<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "_JcIMhvOTVBQ"
   },
   "outputs": [],
   "source": [
    "def check_short_entry_condition(row, previous_row):\n",
    "    return row['close'] < row['Trend'] and row['EMAf'] < row['EMAs'] and previous_row['EMAf'] > previous_row['EMAs'] and row['RSI'] > 30\n",
    "\n",
    "\n",
    "def check_short_exit_condition(row, previous_row):\n",
    "    return row['EMAf'] > row['EMAs'] and previous_row['EMAf'] < previous_row['EMAs']\n",
    "\n",
    "\n",
    "def compute_short_sl_level(row, entry_price):\n",
    "    return entry_price + 2 * row['ATR']\n",
    "\n",
    "\n",
    "def compute_short_tp_level(row, entry_price, stop_loss_price):\n",
    "    risk_reward_ratio = 4\n",
    "    return entry_price * (1 - risk_reward_ratio * (stop_loss_price / entry_price - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmF1hYyMTcfB"
   },
   "source": [
    "**<h5>Core Functions<h5>**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "G8cHv-e9Tytl"
   },
   "outputs": [],
   "source": [
    "def calculate_position_size(balance, exposure, entry_price, stop_loss_price):\n",
    "    if exposure == 'all':\n",
    "        return balance\n",
    "    risked_amount = balance * (exposure / 100)\n",
    "    position = risked_amount * entry_price / abs(entry_price - stop_loss_price)\n",
    "    return min(balance, position)\n",
    "\n",
    "\n",
    "def calculate_liquidation_price(price, leverage, order_type):\n",
    "        if order_type == 'long':\n",
    "            return price * (1 - 1 / leverage)\n",
    "        elif order_type == 'short':\n",
    "            return price * (1 + 1 / leverage)\n",
    "\n",
    "\n",
    "def calculate_pnl(entry_price, exit_price, quantity, order_type):\n",
    "    if order_type == 'long':\n",
    "        return (exit_price - entry_price) * quantity\n",
    "    elif order_type == 'short':\n",
    "        return (entry_price - exit_price) * quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vNk2TyQqT8QO"
   },
   "outputs": [],
   "source": [
    "def record_order(timestamp, type, price, amount, pnl, wallet, fee, orders):\n",
    "    order = {\n",
    "        'timestamp': timestamp,\n",
    "        'type': type,\n",
    "        'amount': amount,\n",
    "        'fee': fee,\n",
    "        'pnl': pnl,\n",
    "        'wallet': wallet,\n",
    "    }\n",
    "    orders.append(order)\n",
    "    print(f\"{type} at {price} {name_quote} on {timestamp}, amount = {round(amount,2)} {name_quote}, pnl = {round(pnl,2)} {name_quote}, wallet = {round(wallet,2)} {name_quote}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HyqOw-n0UF_K"
   },
   "outputs": [],
   "source": [
    "def run_backtest(data):\n",
    "\n",
    "    # Initialize variables\n",
    "    orders = []\n",
    "    order_in_progress = None\n",
    "    last_ath = 0\n",
    "    sl_price = 0\n",
    "    tp_price = 0\n",
    "    long_liquidation_price = 0\n",
    "    short_liquidation_price = 1e10\n",
    "    wallet = initial_capital\n",
    "    data['realised_pnl'] = ''\n",
    "    data['unrealised_pnl'] = ''\n",
    "    data['hodl'] = ''\n",
    "    data['drawdown'] = ''\n",
    "    previous_row = data.iloc[0]\n",
    "\n",
    "\n",
    "    # Go through data and make trades\n",
    "    for index, row in data.iterrows():\n",
    "        price = row['close']\n",
    "\n",
    "\n",
    "        # check if it is time to close a long\n",
    "        if order_in_progress == 'long' and not ignore_longs:\n",
    "            \n",
    "            if row['low'] < long_liquidation_price:\n",
    "                print(f' /!\\\\ Your long was liquidated on the {row[\"timestamp\"]} (price = {long_liquidation_price} {name_quote})')\n",
    "                pnl = calculate_pnl(entry_price, long_liquidation_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * long_liquidation_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'long liquidation', long_liquidation_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_sl and row['low'] <= sl_price:\n",
    "                pnl = calculate_pnl(entry_price, sl_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * sl_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'long sl', sl_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_tp and row['high'] >= tp_price:\n",
    "                pnl = calculate_pnl(entry_price, tp_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * tp_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'long tp', tp_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_exit and check_long_exit_condition(row, previous_row):\n",
    "                pnl = calculate_pnl(entry_price, price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'long exit', price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            if wallet > last_ath:\n",
    "                last_ath = wallet\n",
    "\n",
    "\n",
    "        # check if it is time to close a short\n",
    "        elif order_in_progress == 'short' and not ignore_shorts:\n",
    "            if row['high'] > short_liquidation_price:\n",
    "                print(f' /!\\\\ Your short was liquidated on the {row[\"timestamp\"]} (price = {short_liquidation_price} {name_quote})')\n",
    "                pnl = calculate_pnl(entry_price, short_liquidation_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * short_liquidation_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'short liquidation', short_liquidation_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_sl and row['high'] >= sl_price:\n",
    "                pnl = calculate_pnl(entry_price, sl_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * sl_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'short sl', sl_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_tp and row['low'] <= tp_price:\n",
    "                pnl = calculate_pnl(entry_price, tp_price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * tp_price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'short tp', tp_price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            elif not ignore_exit and check_short_exit_condition(row, previous_row):\n",
    "                pnl = calculate_pnl(entry_price, price, quantity, order_in_progress)\n",
    "                fee_exit = quantity * price * trade_fees / 100\n",
    "                wallet += position - fee_entry + pnl - fee_exit\n",
    "                record_order(row['timestamp'], 'short exit', price, 0, pnl - fee_exit - fee_entry, wallet, fee_exit, orders)\n",
    "                order_in_progress = None\n",
    "\n",
    "            if wallet > last_ath:\n",
    "                last_ath = wallet\n",
    "\n",
    "\n",
    "        # check it is time to enter a long\n",
    "        if not ignore_longs and order_in_progress == None:\n",
    "            if check_long_entry_condition(row, previous_row):\n",
    "                order_in_progress = 'long'\n",
    "                if not ignore_sl:\n",
    "                    sl_price = compute_long_sl_level(row, price)\n",
    "                if not ignore_tp:\n",
    "                    tp_price = compute_long_tp_level(row, price, sl_price)\n",
    "                entry_price = price\n",
    "                position = calculate_position_size(wallet, exposure, price, sl_price)\n",
    "                amount = position * leverage\n",
    "                fee_entry = amount * trade_fees / 100\n",
    "                quantity = (amount - fee_entry) / price\n",
    "                long_liquidation_price = calculate_liquidation_price(price, leverage, order_in_progress)\n",
    "                if wallet > last_ath:\n",
    "                    last_ath = wallet\n",
    "\n",
    "                wallet -= position\n",
    "                record_order(row['timestamp'], 'long entry', price, amount-fee_entry, -fee_entry, wallet, fee_entry, orders)\n",
    "\n",
    "\n",
    "        # check if it is time to enter a short\n",
    "        if not ignore_shorts and order_in_progress == None:\n",
    "            if check_short_entry_condition(row, previous_row):\n",
    "                order_in_progress = 'short'\n",
    "                if not ignore_sl:\n",
    "                    sl_price = compute_short_sl_level(row, price)\n",
    "                if not ignore_tp:\n",
    "                    tp_price = compute_short_tp_level(row, price, sl_price)\n",
    "                entry_price = price\n",
    "                position = calculate_position_size(wallet, exposure, price, sl_price)\n",
    "                amount = position * leverage\n",
    "                fee_entry = amount * trade_fees / 100\n",
    "                quantity = (amount - fee_entry) / price\n",
    "                short_liquidation_price = calculate_liquidation_price(price, leverage, order_in_progress)\n",
    "                wallet -= position\n",
    "                record_order(row['timestamp'], 'short entry', price, amount-fee_entry, -fee_entry, wallet, fee_entry, orders)\n",
    "\n",
    "\n",
    "        # updating wallet info\n",
    "        data.at[index, 'realised_pnl'] = wallet\n",
    "        data.at[index, 'unrealised_pnl'] = data.at[index, 'realised_pnl']\n",
    "        if order_in_progress != None:\n",
    "            data.at[index, 'unrealised_pnl'] += position + calculate_pnl(entry_price, price, quantity, order_in_progress) #- fee\n",
    "        data.at[index, 'hodl'] = initial_capital / data[\"close\"].iloc[0] * price\n",
    "        data.at[index, 'drawdown'] = (data.at[index, 'unrealised_pnl'] - last_ath) / last_ath if last_ath else 0\n",
    "\n",
    "        previous_row = row\n",
    "\n",
    "    return data, orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sBhyHAFlUWXo"
   },
   "source": [
    "**<h1>Backtest<h1>**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cqrd41wNSJRW"
   },
   "source": [
    "<h3>Run<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "5a2mV43YUgsj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "long entry at 1.11785  on 2020-01-06 03:00:00, amount = 19998000.0 , pnl = -2000.0 , wallet = 0 \n",
      " /!\\ Your long was liquidated on the 2020-01-07 02:00:00 (price = 1.117291075 )\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\KGDFRY\\Forex Trading\\GitHub\\backtesting\\venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3678: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "data, backtest_orders = run_backtest(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UYxUw_-NSJUq"
   },
   "source": [
    "<h3>Analysis<h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFWDuCjSUrIi"
   },
   "outputs": [],
   "source": [
    "\n",
    "## Profits\n",
    "show_unrealised = True\n",
    "show_realised = False\n",
    "show_hodl = False\n",
    "\n",
    "profits_bot_realised = ((data['realised_pnl'] - initial_capital)/initial_capital) * 100\n",
    "profits_bot_unrealised = ((data['unrealised_pnl'] - initial_capital)/initial_capital) * 100\n",
    "profits_hodl = ((data['hodl'] - data.iloc[0]['hodl'])/data.iloc[0]['hodl']) * 100\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n",
    "if show_unrealised:\n",
    "    ax1.plot(data['timestamp'], profits_bot_unrealised, color='gold', label='Bot')\n",
    "if show_realised:\n",
    "    ax1.plot(data['timestamp'], profits_bot_realised, color='gold', label='Bot (realised)', ls= '--')\n",
    "if show_hodl:\n",
    "    ax1.plot(data['timestamp'], profits_hodl, color='purple', label='Hodl')\n",
    "ax1.set_title('Net Profits', fontsize=20)\n",
    "ax1.set_ylabel('Net Profits (%)', fontsize=18)\n",
    "ax1.set_xticklabels([])\n",
    "ax1.legend(fontsize=16)\n",
    "if show_unrealised:\n",
    "    ax2.plot(data['timestamp'], data['unrealised_pnl'], color='gold', label='Bot')\n",
    "if show_realised:\n",
    "    ax2.plot(data['timestamp'], data['realised_pnl'], color='gold', label='Bot (realised)', ls= '--')\n",
    "if show_hodl:\n",
    "    ax2.plot(data['timestamp'], data['hodl'], color='purple', label='Hodl')\n",
    "ax2.set_xlabel('Period', fontsize=18)\n",
    "ax2.set_ylabel('Net Profits (' + name_quote + ')', fontsize=18)\n",
    "ax2.tick_params(axis='both', which='major', labelsize=12, rotation = 45)\n",
    "\n",
    "print(f\" \\n\\n      ** Profits ** \\n\")\n",
    "print(f\" > Period: {data['timestamp'].iloc[0]} -> {data['timestamp'].iloc[-1]} \")\n",
    "print(f\" > Starting balance: {initial_capital} {name_quote}\")\n",
    "print(f\" > Final balance Bot: {round(data.iloc[-1]['unrealised_pnl'],2)} {name_quote}\")\n",
    "print(f\" > Final balance Hodl: {round(data.iloc[-1]['hodl'],2)} {name_quote}\")\n",
    "print(f\" > Bot net profits: {round(profits_bot_unrealised.iloc[-1],2)}%\")\n",
    "print(f\" > Hodl net profits: {round(profits_hodl.iloc[-1],2)}%\")\n",
    "print(f\" > Net profits ratio Bot / Hodl: {round(data.iloc[-1]['unrealised_pnl']/data.iloc[-1]['hodl'],2)}\")\n",
    "\n",
    "\n",
    "## Trades\n",
    "orders = pd.json_normalize(backtest_orders, sep='_')\n",
    "n_orders = len(orders.index)\n",
    "if not ignore_longs:\n",
    "    n_longs = orders['type'].value_counts()['long entry']\n",
    "else:\n",
    "    n_longs = 0\n",
    "if not ignore_shorts:\n",
    "    n_shorts = orders['type'].value_counts()['short entry']\n",
    "else:\n",
    "    n_shorts = 0\n",
    "n_entry_orders = 0\n",
    "if not ignore_longs:\n",
    "    n_entry_orders += orders['type'].value_counts()['long entry']\n",
    "if not ignore_shorts:\n",
    "    n_entry_orders += orders['type'].value_counts()['short entry']\n",
    "\n",
    "n_exit_orders = 0\n",
    "if 'long exit' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['long exit']\n",
    "if 'long tp' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['long tp']\n",
    "if 'long sl' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['long sl']\n",
    "if 'short exit' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['short exit']\n",
    "if 'short tp' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['short tp']\n",
    "if 'short sl' in orders['type'].value_counts():\n",
    "    n_exit_orders += orders['type'].value_counts()['short sl']\n",
    "\n",
    "orders.loc[::2, 'pnl'] = np.nan\n",
    "orders['Win'] = ''\n",
    "orders.loc[orders['pnl']>0,'Win'] = 'Yes'\n",
    "orders.loc[orders['pnl']<=0,'Win'] = 'No'\n",
    "if 'Yes' in orders['Win'].value_counts():\n",
    "    n_pos_trades = orders['Win'].value_counts()['Yes']\n",
    "else:\n",
    "    n_pos_trades = 0\n",
    "if 'No' in orders['Win'].value_counts():\n",
    "    n_neg_trades = orders['Win'].value_counts()['No']\n",
    "else:\n",
    "    n_neg_trades = 0\n",
    "\n",
    "winrate = round(n_pos_trades / (n_pos_trades+n_neg_trades) * 100,2)\n",
    "orders['pnl%'] = orders['pnl'] / (orders['wallet'] - orders['pnl'])  * 100\n",
    "avg_trades = round(orders['pnl%'].mean(),2)\n",
    "avg_pos_trades = round(orders.loc[orders['Win'] == 'Yes']['pnl%'].mean(),2)\n",
    "avg_neg_trades = round(orders.loc[orders['Win'] == 'No']['pnl%'].mean(),2)\n",
    "best_trade = orders['pnl%'].max()\n",
    "when_best_trade = orders['timestamp'][orders.loc[orders['pnl%'] == best_trade].index.tolist()[0]]\n",
    "best_trade = round(best_trade,2)\n",
    "worst_trade = orders['pnl%'].min()\n",
    "when_worst_trade = orders['timestamp'][orders.loc[orders['pnl%'] == worst_trade].index.tolist()[0]]\n",
    "worst_trade = round(worst_trade,2)\n",
    "\n",
    "print(f\" \\n\\n      ** Trades ** \\n\")\n",
    "print(f\" > Orders: {n_orders} ({n_entry_orders} buys, {n_exit_orders} sells)\")\n",
    "print(f\" > Number of closed trades: {n_pos_trades+n_neg_trades}\")\n",
    "print(f\" > Winrate: {winrate}%\")\n",
    "print(f\" > Average trade profits: {avg_trades}%\")\n",
    "print(f\" > Number of winning trades: {n_pos_trades}\")\n",
    "print(f\" > Number of losing trades: {n_neg_trades}\")\n",
    "print(f\" > Average winning trades: {avg_pos_trades}%\")\n",
    "print(f\" > Average losing trades: {avg_neg_trades}%\")\n",
    "print(f\" > Best trade: {best_trade}% on the {when_best_trade}\")\n",
    "print(f\" > Worst trade: {worst_trade}% on the {when_worst_trade}\")\n",
    "\n",
    "\n",
    "## Health\n",
    "worst_drawdown = round(data['drawdown'].min()*100,2)\n",
    "profit_factor = round(abs(orders.loc[orders['pnl'] > 0, 'pnl'].sum() / orders.loc[orders['pnl'] < 0, 'pnl'].sum()),2)\n",
    "return_over_max_drawdown = round(profits_bot_unrealised.iloc[-1] / abs(worst_drawdown),2)\n",
    "\n",
    "print(f\" \\n\\n      ** Health ** \\n\")\n",
    "print(f\" > Maximum drawdown: {worst_drawdown}%\")\n",
    "print(f\" > Profit factor: {profit_factor}\")\n",
    "print(f\" > Return over maximum drawdown: {return_over_max_drawdown}\")\n",
    "\n",
    "\n",
    "## fees\n",
    "total_fee = round(orders['fee'].sum(),2)\n",
    "biggest_fee = round(orders['fee'].max(),2)\n",
    "avg_fee = round(orders['fee'].mean(),2)\n",
    "\n",
    "print(f\" \\n\\n      ** Fees ** \\n\")\n",
    "print(f\" > Total: {total_fee} {name_quote}\")\n",
    "print(f\" > Biggest: {biggest_fee} {name_quote}\")\n",
    "print(f\" > Average: {avg_fee} {name_quote} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
